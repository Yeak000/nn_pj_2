{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/input/fcosss/FCOS\n!ls","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:33:50.075551Z","iopub.execute_input":"2023-05-29T13:33:50.075822Z","iopub.status.idle":"2023-05-29T13:33:51.054284Z","shell.execute_reply.started":"2023-05-29T13:33:50.075797Z","shell.execute_reply":"2023-05-29T13:33:51.053182Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/fcosss/FCOS\nREADME.md  coco_eval.py  demo.py  model\nassets\t   dataloader\t eval.py  train_voc.py\n","output_type":"stream"}]},{"cell_type":"code","source":"from model.fcos import FCOSDetector\nimport torch\nfrom dataloader.VOC_dataset import VOCDataset\nimport math, time\nfrom torch.utils.tensorboard import SummaryWriter\n\ntrain_dataset=VOCDataset(\"/kaggle/input/pascal-voc-2012/VOC2012\",resize_size=[512,800],split='train')\nval_dataset=VOCDataset(\"/kaggle/input/pascal-voc-2012/VOC2012\",resize_size=[512,800],split='val')\n\nmodel=FCOSDetector(mode=\"training\").cuda()","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:34:34.556355Z","iopub.execute_input":"2023-05-29T13:34:34.556740Z","iopub.status.idle":"2023-05-29T13:34:52.590161Z","shell.execute_reply.started":"2023-05-29T13:34:34.556707Z","shell.execute_reply":"2023-05-29T13:34:52.589119Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"INFO=====>voc dataset init finished  ! !\nINFO=====>voc dataset init finished  ! !\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 248MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"sum(p.numel() for p in model.fcos_body.head.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2023-05-29T13:40:19.251895Z","iopub.execute_input":"2023-05-29T13:40:19.252315Z","iopub.status.idle":"2023-05-29T13:40:19.260403Z","shell.execute_reply.started":"2023-05-29T13:40:19.252284Z","shell.execute_reply":"2023-05-29T13:40:19.259394Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"4920666"},"metadata":{}}]},{"cell_type":"code","source":"from model.fcos import FCOSDetector\nimport torch\nfrom dataloader.VOC_dataset import VOCDataset\nimport math, time\nfrom torch.utils.tensorboard import SummaryWriter\n\ntrain_dataset=VOCDataset(\"/kaggle/input/pascal-voc-2012/VOC2012\",resize_size=[512,800],split='train')\nval_dataset=VOCDataset(\"/kaggle/input/pascal-voc-2012/VOC2012\",resize_size=[512,800],split='val')\n\nmodel=FCOSDetector(mode=\"training\").cuda()\n# model.load_state_dict(torch.load(\"./checkpoints/voc_512x800_loss2.0635.pth\"))\noptimizer=torch.optim.Adam(model.parameters(),lr=1e-4)\n\nBATCH_SIZE=8\nEPOCHS=12\nWARMPUP_STEPS_RATIO=0.12\ntrain_loader=torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=train_dataset.collate_fn)\nval_loader=torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=val_dataset.collate_fn)\nsteps_per_epoch=len(train_dataset)//BATCH_SIZE\nTOTAL_STEPS=steps_per_epoch*EPOCHS\nWARMPUP_STEPS=TOTAL_STEPS*WARMPUP_STEPS_RATIO\n\nGLOBAL_STEPS=1\nLR_INIT=1e-4\nLR_END=1e-5\n\nwriter=SummaryWriter(log_dir=\"/kaggle/working/logs\")\n\ndef lr_func():\n    if GLOBAL_STEPS<WARMPUP_STEPS:\n        lr=GLOBAL_STEPS/WARMPUP_STEPS*LR_INIT\n    else:\n        lr=LR_END+0.5*(LR_INIT-LR_END)*(\n            (1+math.cos((GLOBAL_STEPS-WARMPUP_STEPS)/(TOTAL_STEPS-WARMPUP_STEPS)*math.pi))\n        )\n    return float(lr)\n\nmodel.train()\n\nfor epoch in range(EPOCHS):\n    for epoch_step,data in enumerate(train_loader):\n\n        batch_imgs,batch_boxes,batch_classes=data\n        batch_imgs=batch_imgs.cuda()\n        batch_boxes=batch_boxes.cuda()\n        batch_classes=batch_classes.cuda()\n\n        lr=lr_func()\n        for param in optimizer.param_groups:\n            param['lr']=lr\n        \n        start_time=time.time()\n\n        optimizer.zero_grad()\n        losses=model([batch_imgs,batch_boxes,batch_classes])\n        loss=losses[-1]\n        loss.backward()\n        optimizer.step()\n\n        end_time=time.time()\n        cost_time=int((end_time-start_time)*1000)\n\n        print(\"global_steps:%d epoch:%d steps:%d/%d cls_loss:%.4f cnt_loss:%.4f reg_loss:%.4f cost_time:%dms lr=%.4e\"%\\\n            (GLOBAL_STEPS,epoch+1,epoch_step+1,steps_per_epoch,losses[0],losses[1],losses[2],cost_time,lr))\n        \n        writer.add_scalar(\"loss/cls_loss\",losses[0],global_step=GLOBAL_STEPS)\n        writer.add_scalar(\"loss/cnt_loss\",losses[1],global_step=GLOBAL_STEPS)\n        writer.add_scalar(\"loss/reg_loss\",losses[2],global_step=GLOBAL_STEPS)\n        writer.add_scalar(\"lr\",lr,global_step=GLOBAL_STEPS)\n\n        GLOBAL_STEPS+=1\n    \n    torch.save(model.state_dict(),\"/kaggle/working/voc2012_512x800_epoch%d_loss%.4f.pth\"%(epoch+1,loss.item()))","metadata":{"execution":{"iopub.status.busy":"2023-05-28T16:08:03.730115Z","iopub.execute_input":"2023-05-28T16:08:03.730484Z","iopub.status.idle":"2023-05-28T16:22:29.030101Z","shell.execute_reply.started":"2023-05-28T16:08:03.730450Z","shell.execute_reply":"2023-05-28T16:22:29.028606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/input/fcosss/FCOS\n!ls","metadata":{"execution":{"iopub.status.busy":"2023-05-29T06:08:37.132016Z","iopub.execute_input":"2023-05-29T06:08:37.132394Z","iopub.status.idle":"2023-05-29T06:08:38.092178Z","shell.execute_reply.started":"2023-05-29T06:08:37.132364Z","shell.execute_reply":"2023-05-29T06:08:38.090992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport torch\nimport numpy as np\nfrom torchvision import transforms\nfrom model.fcos import FCOSDetector\nimport matplotlib.pyplot as plt\ndef preprocess_img(image,input_ksize):\n    '''\n    resize image and bboxes \n    Returns\n    image_paded: input_ksize\n    '''\n    min_side, max_side    = input_ksize\n    h,  w, _  = image.shape\n\n    smallest_side = min(w,h)\n    largest_side=max(w,h)\n    scale=min_side/smallest_side\n    if largest_side*scale>max_side:\n        scale=max_side/largest_side\n    nw, nh  = int(scale * w), int(scale * h)\n    image_resized = cv2.resize(image, (nw, nh))\n\n    pad_w=32-nw%32\n    pad_h=32-nh%32\n\n    image_paded = np.zeros(shape=[nh+pad_h, nw+pad_w, 3],dtype=np.uint8)\n    image_paded[:nh, :nw, :] = image_resized\n    return image_paded\n\nmodel=FCOSDetector(mode=\"inference\")\n# %cd ../..\nmodel.load_state_dict(torch.load(\"/kaggle/input/nn-hw2-inference/voc2012_512x800_epoch7_loss0.8541.pth\",\n                                 map_location=torch.device('cpu')))\nmodel=model.cuda().eval()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-29T06:22:44.866322Z","iopub.execute_input":"2023-05-29T06:22:44.866691Z","iopub.status.idle":"2023-05-29T06:22:45.734751Z","shell.execute_reply.started":"2023-05-29T06:22:44.866662Z","shell.execute_reply":"2023-05-29T06:22:45.733687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-29T06:21:57.712431Z","iopub.execute_input":"2023-05-29T06:21:57.712794Z","iopub.status.idle":"2023-05-29T06:21:57.723511Z","shell.execute_reply.started":"2023-05-29T06:21:57.712766Z","shell.execute_reply":"2023-05-29T06:21:57.721898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.cvtColor(cv2.imread(f'/kaggle/input/nn-hw2-inference/cat.jpg'),cv2.COLOR_BGR2RGB)\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-29T06:35:54.012053Z","iopub.execute_input":"2023-05-29T06:35:54.012444Z","iopub.status.idle":"2023-05-29T06:35:54.053141Z","shell.execute_reply.started":"2023-05-29T06:35:54.012411Z","shell.execute_reply":"2023-05-29T06:35:54.052272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef rescale(box,h,w):\n    min_side, max_side = [512,800]\n    smallest_side = min(w,h)\n    largest_side=max(w,h)\n    scale=min_side/smallest_side\n    if largest_side*scale>max_side:\n        scale=max_side/largest_side\n    box[:, [0, 2]] = box[:, [0, 2]] / scale \n    box[:, [1, 3]] = box[:, [1, 3]] / scale\n    return box\ndef draw(s):\n    plt.figure()\n    c_d = {'person':'blue','cat':'red','dog':'brown'}\n    img = cv2.cvtColor(cv2.imread(f'/kaggle/input/nn-hw2-inference/{s}.jpg'),cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    h,w = img.shape[0],img.shape[1]\n    img = preprocess_img(img,[512,800])\n    img = transforms.ToTensor()(img).unsqueeze(0)\n    with torch.no_grad():\n        out=model(img.cuda())\n    scores = out[0][0]\n    boxes = out[2][0]\n    print(boxes.shape)\n    boxes = rescale(boxes,h,w)\n    print(boxes)\n\n    ax = plt.gca()\n    for i in range(len(scores)):\n        if scores[i].item()>0.5:\n            box = boxes[i]\n            ax.add_patch(plt.Rectangle((box[0].item(), box[1].item()), \n                                       (box[2]-box[0]).item(), (box[3]-box[1]).item(), color=f\"{c_d[s]}\", fill=False, linewidth=1))\n            ax.text(box[0].item(), box[1].item(), f\"{s} {round(scores[i].item(),2)}\", bbox={'facecolor':f\"{c_d[s]}\", 'alpha':0.5})\n    plt.savefig(f\"/kaggle/working/{s}_fcos.jpg\")\ndraw('person')\ndraw('cat')\ndraw('dog')","metadata":{"execution":{"iopub.status.busy":"2023-05-29T06:39:56.232102Z","iopub.execute_input":"2023-05-29T06:39:56.232797Z","iopub.status.idle":"2023-05-29T06:39:58.175969Z","shell.execute_reply.started":"2023-05-29T06:39:56.232760Z","shell.execute_reply":"2023-05-29T06:39:58.174927Z"},"trusted":true},"execution_count":null,"outputs":[]}]}